{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from typing import Literal\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1736515293034, 1736515293034)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "\n",
    "int(datetime.datetime.now().timestamp() * 1000), int(time() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"1736515037.656000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4472135954999579, 0.8944271909999159)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def normalized_vector(vector: list):\n",
    "    try:\n",
    "        x, y = vector\n",
    "        magnitude = math.sqrt(x**2 + y**2)\n",
    "        return (x / magnitude, y / magnitude)\n",
    "    except ZeroDivisionError:\n",
    "        return (0, 0)\n",
    "\n",
    "\n",
    "x, y = normalized_vector([1, 2])\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = 1\n",
    "A = 1\n",
    "B = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 3\n",
    "Y = 100\n",
    "\n",
    "new_speed = (\n",
    "    math.sqrt(((X * x) ** 2 + (Y * y) ** 2) / ((A * x) ** 2 + (B * y) ** 2)) * speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.45278083994931"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_duration = math.sqrt(A**2 + (B * 2) ** 2) / speed\n",
    "new_duration = math.sqrt(X**2 + (Y * 2) ** 2) / new_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.23606797749979, 2.2360679774997894)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_duration, new_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def check():\n",
    "        pass\n",
    "\n",
    "\n",
    "class B(A):\n",
    "    def check(self):\n",
    "        print(\"Hello\")\n",
    "\n",
    "\n",
    "b = B()\n",
    "\n",
    "b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextUtilities:\n",
    "    STOPWORDS = set(\n",
    "        [\n",
    "            \"the\",\n",
    "            \"be\",\n",
    "            \"to\",\n",
    "            \"of\",\n",
    "            \"and\",\n",
    "            \"a\",\n",
    "            \"in\",\n",
    "            \"that\",\n",
    "            \"have\",\n",
    "            \"i\",\n",
    "            \"it\",\n",
    "            \"for\",\n",
    "            \"not\",\n",
    "            \"on\",\n",
    "            \"with\",\n",
    "            \"he\",\n",
    "            \"as\",\n",
    "            \"you\",\n",
    "            \"do\",\n",
    "            \"at\",\n",
    "            \"this\",\n",
    "            \"but\",\n",
    "            \"his\",\n",
    "            \"by\",\n",
    "            \"from\",\n",
    "            \"wikipedia\",\n",
    "        ]\n",
    "    )\n",
    "    PUNCTUATION = re.compile(\"[%s]\" % re.sub(r\"[.\\-\\/]\", \"\", string.punctuation))\n",
    "    __MARKED = \"ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝàáâãèéêìíòóôõùúýĂăĐđĨĩŨũƠơƯưẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹ\"\n",
    "    __NO_MARKED = \"AAAAEEEIIOOOOUUYaaaaeeeiioooouuyAaDdIiUuOoUuAaAaAaAaAaAaAaAaAaAaAaAaEeEeEeEeEeEeEeEeIiIiOoOoOoOoOoOoOoOoOoOoOoOoUuUuUuUuUuUuUuYyYyYyYy\"\n",
    "\n",
    "    def __tokenize__(self, text: str):\n",
    "        tokens = text.split()\n",
    "        res = []\n",
    "        for to in tokens:\n",
    "            res.extend(to.split(\"…\"))\n",
    "        return res\n",
    "\n",
    "    def __remove_punctuations__(self, text: str):\n",
    "        tokens = self.__tokenize__(text)\n",
    "        temp = [self.PUNCTUATION.sub(\"\", t) for t in tokens]\n",
    "        return \" \".join(temp)\n",
    "\n",
    "    def __trim__(self, text: str):\n",
    "        tokens = self.__tokenize__(text)\n",
    "        rm_white = [t for t in tokens if t != \"\"]\n",
    "        return \" \".join(rm_white)\n",
    "\n",
    "    def __longest_substring_of_two__(self, string1, string2):\n",
    "        answer = \"\"\n",
    "        len1, len2 = len(string1), len(string2)\n",
    "        for i in range(len1):\n",
    "            for j in range(len2):\n",
    "                lcs_temp = 0\n",
    "                match = \"\"\n",
    "                while (\n",
    "                    (i + lcs_temp < len1)\n",
    "                    and (j + lcs_temp < len2)\n",
    "                    and string1[i + lcs_temp] == string2[j + lcs_temp]\n",
    "                ):\n",
    "                    match += string2[j + lcs_temp]\n",
    "                    lcs_temp += 1\n",
    "                if len(match) > len(answer):\n",
    "                    answer = match\n",
    "\n",
    "        return self.analyze(answer)\n",
    "\n",
    "    def __remove_accent__(self, text: str):\n",
    "        s = \"\"\n",
    "        for c in text:\n",
    "            if c in self.__MARKED:\n",
    "                s += self.__NO_MARKED[self.__MARKED.index(c)]\n",
    "            else:\n",
    "                s += c\n",
    "        return s\n",
    "\n",
    "    def analyze(self, text, remove_accent=False):\n",
    "        return self.__trim__(\n",
    "            self.__remove_punctuations__(\n",
    "                self.__remove_accent__(text) if remove_accent else text\n",
    "            )\n",
    "        ).lower()\n",
    "\n",
    "    def find_longest_substring(self, list_strings: list[str]):\n",
    "        str_len = len(list_strings)\n",
    "        if str_len % 2 == 1:\n",
    "            list_strings.append(list_strings[str_len - 1])\n",
    "\n",
    "        list_res: list[str] = []\n",
    "\n",
    "        for index, value in enumerate(list_strings):\n",
    "            if index % 2 == 0:\n",
    "                next = list_strings[index + 1]\n",
    "                temp = self.__longest_substring_of_two__(value, next)\n",
    "                list_res.append(temp)\n",
    "\n",
    "        if len(list_res) == 1:\n",
    "            return list_res[0]\n",
    "\n",
    "        return self.find_longest_substring(list_strings=list_res)\n",
    "\n",
    "    def synthetic_string(\n",
    "        self, list_strings: list[str], format: Literal[\"dict\", \"string\"]\n",
    "    ):\n",
    "        enums: list[str] = []\n",
    "\n",
    "        for s in list_strings:\n",
    "            temp = self.__tokenize__(self.analyze(s))\n",
    "            enums.extend(temp)\n",
    "\n",
    "        enums = np.unique(enums)\n",
    "\n",
    "        if format == \"dict\":\n",
    "            return enums\n",
    "\n",
    "        return \" \".join(enums)\n",
    "\n",
    "\n",
    "text_utils = TextUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = re.compile(\"[%s]\" % re.sub(r\"[.\\-\\/]\", \"\", string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sub(\"\", \"trạng trình, ngôi đền thiêng liêng. Nằm tại Hải phòng. Từ ngày 27-29/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://thanhdoanhaiphong.gov.vn/khu-di-tich-quoc-gia-dac-biet-den-tho-trang-trinh-nguyen-binh-khiem-nd22925.html\"\n",
    "\n",
    "\n",
    "html = urlopen(url).read()\n",
    "soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "# kill all script and style elements\n",
    "for script in soup([\"script\", \"style\"]):\n",
    "    script.extract()  # rip it out\n",
    "\n",
    "# get text\n",
    "text = soup.get_text()\n",
    "# text = text_utils.analyze(text)\n",
    "\n",
    "# # break into lines and remove leading and trailing space on each\n",
    "# lines = (line.strip() for line in text.splitlines())\n",
    "# # break multi-headlines into a line each\n",
    "# chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# # drop blank lines\n",
    "# text = \"\\n\".join(chunk for chunk in chunks if chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"text.txt\", \"w\")\n",
    "\n",
    "fd.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"text\"])\n",
    "\n",
    "for i in range(len(tokens) - 2):\n",
    "    df.loc[len(df.index)] = [\" \".join(tokens[i : i + 3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\n\\n\\thello\\tworld\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "tokens = fd.read().split(\"\\n\")\n",
    "for to in tokens:\n",
    "    to = text_utils.analyze(to)\n",
    "    if to != \"\":\n",
    "        if to[-1] != \".\":\n",
    "            to = to + \".\"\n",
    "        res.append(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strings = text_utils.analyze(\" \".join(res)).split(\". \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={df.columns[0]: \"title\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"text_nbk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./text_nbk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text: str = row.text\n",
    "    tokens = text.split()\n",
    "    df.loc[index, [\"text\", \"target\"]] = [\" \".join(tokens[:2]), tokens[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, train_size=0.8, shuffle=True)\n",
    "train, val = train_test_split(train, train_size=7 / 8, shuffle=True)\n",
    "for index in df.index:\n",
    "    if index in train.index:\n",
    "        df.loc[index, \"split\"] = \"train\"\n",
    "    elif index in val.index:\n",
    "        df.loc[index, \"split\"] = \"val\"\n",
    "    elif index in test.index:\n",
    "        df.loc[index, \"split\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import pytz\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "now.astimezone(pytz.timezone(\"Asia/Ho_Chi_Minh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "softmax([1, 5, 10, 2, 4, 2, 1, 1, 1], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
